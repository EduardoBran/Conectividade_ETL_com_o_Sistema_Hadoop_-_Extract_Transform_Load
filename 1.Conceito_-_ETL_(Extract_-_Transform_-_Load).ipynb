{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add3d876",
   "metadata": {},
   "source": [
    "# <center><span style=\"font-size: 42px;color: darkgreen;\">Conceito Sobre <u>ETL</u> (*Extract* - *Transform* - *Load*)</center></span>\n",
    "\n",
    "<br>\n",
    "\n",
    "Em qualquer projeto de **Análise de Dados**, seja com **Big Data** ou não, uma tarefa é sempre essencial: o **ETL**.\n",
    "\n",
    "As **Operações de ETL** (*Extract*, *Transform*, *Load*) são um processo de **extração de dados** de uma fonte, seguido pela **transformação** dos dados para atender a requisitos específicos e, finalmente, o **carregamento** dos dados em um repositório. Esse repositório é então utilizado para o **processo de análise**.\n",
    "\n",
    "O **ETL** é especialmente comum em ambientes de *BI* (*Business Intelligence*), sendo amplamente utilizado para a criação de **Data Marts** (conjuntos de dados específicos para uma área de negócios, como vendas ou marketing, dentro de uma organização) e **Data Warehouses** (repositórios de dados centralizados e estruturados para toda a organização, que integram informações de múltiplas fontes para análise e tomada de decisões estratégicas).\n",
    "\n",
    "O **Hadoop** possui duas ferramentas principais em seu ecossistema:\n",
    " - `Apache Sqoop`: Normalmente usado para **carga de dados em batch** (em lotes), transferindo grandes volumes de dados de bancos de dados relacionais para o Hadoop, facilitando a movimentação de dados estruturados.\n",
    " - `Apache Flume`: Ideal para a **ingestão de dados em tempo real, especialmente dados de log**. O `Flume` é amplamente utilizado para coletar e agregar dados de fontes contínuas e não estruturadas, como logs de servidores e eventos em tempo real.\n",
    " \n",
    "O **Apache Sqoop** será estudado neste capítulo.\n",
    " \n",
    "<br><br>\n",
    "\n",
    "### O que é ETL (*Extract* - *Transform* - *Load*) ?\n",
    "\n",
    "<br>\n",
    "\n",
    "O **ETL** é um processo de integração de dados que envolve três etapas principais: **extração**, **transformação** e **carga** dos dados. Ele permite mover dados de uma ou várias fontes para um destino, onde esses dados serão analisados.\n",
    "\n",
    "- **Extract (Extrair)**: Nessa etapa, os dados são obtidos de suas fontes, que podem variar amplamente, como bancos de dados, APIs, ou arquivos. Cada fonte pode exigir um **método específico de extração** (login com usuário e senha, comandos específicos, ou chamada de APIs), de acordo com suas características.\n",
    "\n",
    "- **Transform (Transformar)**: Esta etapa garante que os dados estejam consistentes e prontos para uso. Transformar é importante porque os dados geralmente vêm desorganizados ou em diferentes formatos. Por exemplo, dados de um formulário web podem estar com formatos variados devido à ausência de validação no preenchimento. A transformação inclui **limpar**, **padronizar** e **estruturar** os dados, preparando-os para a análise.\n",
    "\n",
    "- **Load (Carregar)**: Aqui, os dados já transformados são carregados no sistema de destino, como um **data warehouse** ou **data lake**. Este é o passo final que disponibiliza os dados prontos para consulta e análise.\n",
    "\n",
    "<br>\n",
    "\n",
    "O **ETL** é fundamental para preparar dados de forma consistente e confiável para **Business Intelligence** e **Análise de Dados**, integrando informações de múltiplas fontes em um único repositório para insights e tomada de decisões.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Principais Ferramentas ETL do Mercado\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Principais Ferramentas Propietárias (Pagas)\n",
    "\n",
    "- Informatica Power Center\n",
    "- IBM InfoSphere Data Stage\n",
    "- Oracle Data Integrator (ODI)\n",
    "- Microsoft - SQL Server Integration Services (SSIS)\n",
    "- SAS - Data Integration Studio\n",
    "- SAP - Business Object Integrator\n",
    "- Pentaho Data Integration\n",
    "\n",
    "---\n",
    "\n",
    "#### Principais Ferramentas Open Source (Gratuitas\n",
    "\n",
    "- Dataiku Data Science Studio (DSS) *Community Edition*\n",
    "- Talend Open Studio For Data Integration\n",
    "- Jaspersoft ETL\n",
    "- Jedox\n",
    "- RapidMiner\n",
    "- Apache NiFi\n",
    "- Apache Flume\n",
    "- Apache Sqoop\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c32c6a",
   "metadata": {},
   "source": [
    "# Instalação Banco Oracle\n",
    "\n",
    "## Oracle 19c - Instalação\n",
    "\n",
    "--- \n",
    "\n",
    "### 1- Efetuar login como usuário root\n",
    "su\n",
    "cd ~\n",
    "\n",
    "### 2- Atualizar o SO\n",
    "yum update -y\n",
    "\n",
    "### 3- Editar o arquivo /etc/hosts e incluir o nome da máquina como FQDN com o IP da VM (não usar localhost)\n",
    "echo \"192.168.122.1 dataserver.localdomain\" >> /etc/hosts\n",
    "\n",
    "### 4- Editar o arquivo /etc/sysctl.conf e incluir as linhas abaixo\n",
    "echo -e \"# Oracle\\nfs.file-max = 6815744\\nkernel.sem = 250 32000 100 128\\nkernel.shmmni = 4096\\nkernel.shmall = 1073741824\\nkernel.shmmax = 4398046511104\\nkernel.panic_on_oops = 1\\nnet.core.rmem_default = 262144\\nnet.core.rmem_max = 4194304\\nnet.core.wmem_default = 262144\\nnet.core.wmem_max = 1048576\\nnet.ipv4.conf.all.rp_filter = 2\\nnet.ipv4.conf.default.rp_filter = 2\\nfs.aio-max-nr = 1048576\\nnet.ipv4.ip_local_port_range = 9000 65500\" >> /etc/sysctl.conf\n",
    "\n",
    "### 5- Efetivar as alterações do item 4\n",
    "/sbin/sysctl -p\n",
    "\n",
    "### 6- Adicionar as linhas abaixo para o arquivo /etc/security/limits.conf\n",
    "echo -e \"# Oracle\\noracle soft nofile 1024\\noracle hard nofile 65536\\noracle soft nproc 16384\\noracle hard nproc 16384\\noracle soft stack 10240\\noracle hard stack 32768\\noracle hard memlock 134217728\\noracle soft memlock 134217728\" >> /etc/security/limits.conf\n",
    "\n",
    "### 7- Instalar os pacotes necessários no SO\n",
    "yum install -y bc binutils compat-libcap1 compat-libstdc++-33 elfutils-libelf elfutils-libelf-devel fontconfig-devel glibc glibc-devel ksh libaio libaio-devel libdtrace-ctf-devel libXrender libXrender-devel libX11 libXau libXi libXtst libgcc librdmacm-devel libstdc++ libstdc++-devel libxcb make net-tools nfs-utils smartmontools sysstat unixODBC\n",
    "\n",
    "### 8- Criar os grupos no SO\n",
    "groupadd -g 54321 oinstall\n",
    "groupadd -g 54322 dba\n",
    "groupadd -g 54323 oper\n",
    "\n",
    "### 9- Adicionar usuário owner da instalação Oracle\n",
    "useradd -u 54321 -g oinstall -G dba,oper oracle\n",
    "echo \"Bon_t__10!\" | passwd --stdin oracle\n",
    "\n",
    "### 10- Editar o arquivo /etc/selinux/config e definir SELINUX=permissive\n",
    "sed -i 's/^SELINUX=.*/SELINUX=permissive/' /etc/selinux/config\n",
    "setenforce Permissive\n",
    "\n",
    "### 11- Desativar o firewall\n",
    "systemctl stop firewalld\n",
    "systemctl disable firewalld\n",
    "\n",
    "### 12- Criar os diretórios de instalação\n",
    "mkdir -p /u01/app/oracle/product/19.0.0/dbhome_1\n",
    "mkdir -p /u02/oradata\n",
    "chown -R oracle:oinstall /u01 /u02\n",
    "chmod -R 775 /u01 /u02\n",
    "\n",
    "### 13- Criar um diretório de scripts\n",
    "mkdir /home/oracle/scripts\n",
    "\n",
    "### 14- Criar o arquivo de variáveis do usuário Oracle\n",
    "echo -e \"# Oracle\\nexport TMP=/tmp\\nexport TMPDIR=\\$TMP\\nexport ORACLE_HOSTNAME=dataserver.localdomain\\nexport ORACLE_UNQNAME=orcl\\nexport ORACLE_BASE=/u01/app/oracle\\nexport ORACLE_HOME=\\$ORACLE_BASE/product/19.0.0/dbhome_1\\nexport ORA_INVENTORY=/u01/app/oraInventory\\nexport ORACLE_SID=orcl\\nexport DATA_DIR=/u02/oradata\\nexport PATH=/usr/sbin:/usr/local/bin:\\$PATH\\nexport PATH=\\$ORACLE_HOME/bin:\\$PATH\\nexport LD_LIBRARY_PATH=\\$ORACLE_HOME/lib:/lib:/usr/lib\\nexport CLASSPATH=\\$ORACLE_HOME/jlib:\\$ORACLE_HOME/rdbms/jlib\" > /home/oracle/scripts/setEnv.sh\n",
    "\n",
    "### 15- Adicionar variáveis de ambiente ao profile do usuário oracle\n",
    "echo \". /home/oracle/scripts/setEnv.sh\" >> /home/oracle/.bash_profile\n",
    "\n",
    "# 16- Efetuar login como usuário oracle, fazer download e instalar Oracle 19c (O download deve ser feito manualmente e colocado em /home/oracle/Downloads/)\n",
    "\n",
    "su - oracle\n",
    "cd $ORACLE_HOME\n",
    "unzip -oq /home/oracle/Downloads/LINUX.X64_193000_db_home.zip\n",
    "./runInstaller\n",
    "\n",
    "### Siga as instruções de instalação conforme descrito\n",
    "\n",
    "#### Obs: Se receber mensagem de erro durante a instalação, abra um terminal e adicione as linhas abaixo no arquivo /home/oracle/.bashrc e não esqueça de executar source .bashrc. Depois clique em Retry no instalador.\n",
    "\n",
    "export JAVA_HOME=/opt/jdk\n",
    "export PATH=$PATH:$JAVA_HOME/bin\n",
    "\n",
    "\n",
    "\n",
    "- Deixar marcado a primeira opção \"Create and configure...\" e clicar em Next\n",
    "- Deixar marcado Desktop class e clicar em Next\n",
    "- Adicionar uma senha e desmarcar a opcao \"Create as Container database\" e clicar em Next\n",
    "- Na sequência deixar Inventory Directory como está e clicar em Next\n",
    "- Marcar a opção \"Automatically run configuration scripts\" e digitar a senha do root e clicar em Next\n",
    "- Será exibido dois avisos de warning, marcar a caixa 'Ignore All' e clicar em Next. Na sequência clicar em Yes para realmente ignorar.\n",
    "- Depois será exibido um resumo da instalação. Clicar então em Install\n",
    "\n",
    "### 17 - Checar o status e iniciar o listener\n",
    "\n",
    "lsnrctl status\n",
    "\n",
    "lsnrctl start\n",
    "\n",
    "lsnrctl stop\n",
    "\n",
    "### 18- Conectar ao Banco de Dados e registrar no listener\n",
    "\n",
    "sqlplus / as sysdba\n",
    "show parameter local_listener\n",
    "alter system set local_listener='(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.122.1)(PORT=1539))';\n",
    "ALTER SYSTEM REGISTER;\n",
    "exit\n",
    "\n",
    "lsnrctl status\n",
    "\n",
    "### 19- Criar o arquivo /u01/app/oracle/product/19.0.0/dbhome_1/network/admin/tnsnames.ora\n",
    "cd /u01/app/oracle/product/19.0.0/dbhome_1/network/admin/\n",
    "echo -e \"orcl= \\n (DESCRIPTION= \\n   (ADDRESS=(PROTOCOL=tcp)(HOST=dataserver.localdomain)(PORT=1539))\\n   (CONNECT_DATA= \\n     (SERVICE_NAME=orcl)))\" > tnsnames.ora\n",
    "\n",
    "### 20- Testar a conexão\n",
    "tnsping orcl\n",
    "\n",
    "### 21- Parar ou Iniciar o Banco\n",
    "\n",
    "#### Parar\n",
    "\n",
    "Parar   -> lsnrctl stop\n",
    "\n",
    "Checar  -> lsnrctl status\n",
    "\n",
    "Acessar -> sqlplus / as sysdba e digitar -> shutdown immediate\n",
    "\n",
    "exit\n",
    "\n",
    "\n",
    "#### Iniciar\n",
    "\n",
    "Iniciar -> lsnrctl start\n",
    "\n",
    "Acessar -> sqlplus / as sysdba e digitar -> startup\n",
    "\n",
    "exit\n",
    "\n",
    "#### Checar\n",
    "\n",
    "Checar  -> lsnrctl status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749f851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ce217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a51279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1f259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782df04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a127bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
